{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Ironhack logo](https://i.imgur.com/1QgrNNw.png)\n",
    "\n",
    "\n",
    "# Supervised Learning Project\n",
    "\n",
    "**by Octavio Garcia**\n",
    "\n",
    "A continuación se detallan las fases desarrolladas dentro de un proyecto de 'aprendizaje supervisado multiclase'. Los requerimientos del proyecto son los siguientes:\n",
    "\n",
    "- Problema multiclase (utilización del módulo OneVsRestClassifier de sklearn).\n",
    "\n",
    "- Análisis previo de los datos (balance entre clases).\n",
    "\n",
    "- Entrenamiento de 2 modelos de ml.\n",
    "\n",
    "- Extracción de métricas: Accuracy, Precision, Recall, F1Score, ROC, AUC, Confussion Matrix.\n",
    "\n",
    "Para responder a los requerimientos se ha realizado un 'pipeline' que incluye:\n",
    "\n",
    "- **Fase 1:** Elección y análisis inicial del dataset.\n",
    "\n",
    "- **Fase 2:** Preparación del dataset para evaluación de los modelos elegidos.\n",
    "\n",
    "- **Fase 3:** Obtención de métricas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importanción de librerías utilizadas en el desarrollo del proyecto.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from scipy import interp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fase 1: Elección y análisis inicial del dataset.\n",
    "\n",
    "Se ha elegido un dataset que incluye las estadísticas de baseball, concretamente las estadísticas de bateo por jugador de toda la historia de la Major League Baseball. Dichas estadísticas son valores numéricos que corresponden al desempeño ofensivo de cada jugador durante una temporada completa, sumando un total de 17 estadísticas de bateo más otros dos valores numéricos (año y stint, el cual es un identificador de si el jugador ha estado en más de un equipo en un año).\n",
    "\n",
    "Asimismo, el dataset incluye features categóricas que corresponden al identificador del jugador, el equipo en el que juega y la liga a la que pertenece el equipo. El clasificador se aplicará sobre el equipo donde juega el jugador de manera que el modelo sea capaz de predecir en que equipo ha jugado un jugador en función de sus estadísticas de bateo. \n",
    "\n",
    "![Ironhack logo](moneyball.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importanción del dataset.\n",
    "bat = pd.read_csv('./Batting.csv')#,encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualización del dataset.\n",
    "bat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tamaño del dataset (105861 registros con 22 columnas)\n",
    "bat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tipo de datos del dataset\n",
    "bat.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualización de valores nulos.\n",
    "bat.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Análisis de las variables categóricas. Se crea una función para analizar las variables categóricas.\n",
    "def selected_feat(selected,df):\n",
    "    values = []\n",
    "    leng = selected.shape\n",
    "    for i in range(leng[0]):\n",
    "        values.append(df[selected[i]].unique())\n",
    "        new_df = pd.DataFrame(values).T\n",
    "    new_df.columns = [i for i in selected]\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables categóricas a análizar.\n",
    "object_col = np.array(['teamID','lgID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resultado del análisis de las variables categóricas.\n",
    "selected_feat(object_col,bat).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminación de los registros con valores nulos.\n",
    "bat.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificación de que no existen registros con valores nulos.\n",
    "bat.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Se analizan nuevamente las columnas categóricas.\n",
    "selected_feat(object_col,bat).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se verifica cuan balancedos están los datos por equipos.\n",
    "bat.teamID.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FILTRADO DE DATOS:\n",
    "\n",
    "El dataset incluye estadísticas de toda la historia de la MLB, sin embargo, existen muchos equipos en los albores de la historia de la MLB que fueron desapareciendo y equipos que han cambiado de ciudad y propietario pero que realmente son los mismos (i.e.: cambio de franquicia). También, han habido cambios importantes en las reglas del juego por lo que he decidido trabajar solamente con los registros posteriores a 1975, año en el que se realizaron las últimas modificaciones importantes al juego. Este filtro también elimina muchos equipos con bajo número de registros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminación de registros anteriores a 1975.\n",
    "bat_1975 = bat[bat.yearID >= 1975]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reasignación de nombres de las columnas juntando las franquicias bajo un mismo nombre de equipo.\n",
    "TEAMS = {'TEX':'Texas Rangers','NYA':'New York Yankees','CLE':'Cleveland Indians','NYN':'New York Mets',\n",
    "         'SDN':'San Diego Padres','OAK':'Oakland Athletics','BOS':'Boston Red Sox','PIT':'Pittsburgh Pirates',\n",
    "         'LAN':'Los Angeles Dodgers','KCA':'Kansas City Royals','BAL':'Baltimore Orioles',\n",
    "         'PHI':'Philadelphia Phillies','CIN':'Cincinnati Reds','ATL':'Atlanta Braves','CHN':'Chicago Cubs',\n",
    "         'SFN':'San Francisco Giants','SEA':'Seattle Mariners','DET':'Detroit Tigers','CHA':'Chicago White Sox',\n",
    "         'SLN':'St. Louis Cardinals','TOR':'Toronto Blue Jays','HOU':'Houston Astros','MIN':'Minnesota Twins',\n",
    "         'MON':'Montreal Expos','COL':'Colorado Rockies','ARI':'Arizona Diamondbacks','TBA':'Tampa Bay Rays',\n",
    "         'MIL':'Milwaukee Brewers','CAL':'Los Angeles Angels','ML4':'Milwaukee Brewers','FLO':'Miami Marlins',\n",
    "         'WAS':'Washington Nationals','LAA':'Los Angeles Angels','MIA':'Miami Marlins','ANA':'Los Angeles Angels'}\n",
    "bat_1975.replace({'teamID':TEAMS},inplace=True)\n",
    "#Ahora el total de equipos es el total de equipos actuales más los Expos de Montreal que desaparecieron en 2004.\n",
    "bat_1975['teamID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bat_1975.teamID.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop pitchers or no-batters\n",
    "bat_AB = bat_1975[bat_1975.AB != 0]#.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "champs = pd.read_csv('./Champions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_df = pd.DataFrame(champs.CHAMPION.value_counts().reset_index())\n",
    "ws_df.rename(columns={'index':'Team','CHAMPION':'WorldSeriesTotal'},inplace=True)\n",
    "ws_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_df['Team'].str.contains(bat_1975['teamID'].unique()[0]).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WorldSeries(team):\n",
    "    equipo = str(team)\n",
    "    if ws_df['Team'].str.contains(equipo).any() == True:\n",
    "        if (ws_df.loc[ws_df['Team'] == equipo, 'WorldSeriesTotal'].iloc[0]) > 3:\n",
    "            team = 'G1 World Series Team'\n",
    "        elif 2 <= (ws_df.loc[ws_df['Team'] == equipo, 'WorldSeriesTotal'].iloc[0]) <= 3:\n",
    "            team = 'G2 World Series Team'\n",
    "        elif (ws_df.loc[ws_df['Team'] == equipo, 'WorldSeriesTotal'].iloc[0]) == 1:\n",
    "            team = 'G3 World Series Team'\n",
    "        return team\n",
    "    else:\n",
    "        team = \"No World Series Team\"\n",
    "        return team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WorldSeries('Cincinnati Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bat_AB['WorldSeries'] = bat_AB['teamID'].apply(WorldSeries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bat_AB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bat_AB.WorldSeries.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping useless columns\n",
    "bat_df = bat_AB.drop(['playerID','lgID','teamID'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATS = {'G':'Games','AB':'At Bat','R':'Runs Scored','H':'Hits','2B':'Double','3B':'Triple',\n",
    "         'HR':'Home Runs','RBI':'Run Batted In','SB':'Stolen Base','CS':'Caught Stealing',\n",
    "         'BB':'Base on Balls','SO':'Strike Out','IBB':'Intentional Base on Balls','HBP':'Hit By Pitch',\n",
    "         'SH':'Sacrifice Hit','SF':'Sacrifice Fly','GIDP':'Double Plays Induced'}\n",
    "bat_df.rename(columns=STATS,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bat_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bat_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_columns = [col for col in bat_df.columns.values if col != 'WorldSeries']\n",
    "X = bat_df[X_columns]\n",
    "display(X.shape,X.head(),X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(data=bat_df['WorldSeries'])\n",
    "display(y.shape,y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "a4_dims = (11.7, 8.27)\n",
    "fig, ax = pyplot.subplots(figsize=a4_dims)\n",
    "sns.set()\n",
    "ax = sns.heatmap(X.corr())\n",
    "'''\n",
    "mask = np.zeros_like(X.corr(), dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "fig, ax = plt.subplots(figsize=(12,10))\n",
    "ax = sns.heatmap(X.corr(), mask=mask, annot=True, cmap=\"BuPu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X.drop(['Games', 'At Bat', 'Runs Scored', 'Hits', 'Double',\n",
    "       'Home Runs', 'Run Batted In', 'Caught Stealing',\n",
    "       'Base on Balls', 'Strike Out', \n",
    "       'Sacrifice Fly',\n",
    "       'Double Plays Induced'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "a4_dims = (11.7, 8.27)\n",
    "fig, ax = pyplot.subplots(figsize=a4_dims)\n",
    "sns.set()\n",
    "ax = sns.heatmap(X.corr())\n",
    "'''\n",
    "\n",
    "mask = np.zeros_like(X.corr(), dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "fig, ax = plt.subplots(figsize=(12,10))\n",
    "ax = sns.heatmap(X.corr(), mask=mask, annot=True, cmap=\"BuPu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression multilabel model function with crossvalidation\n",
    "def LRs(X,y,ns):\n",
    "    cls = OneVsRestClassifier(LogisticRegression(solver='liblinear'))\n",
    "    scores = cross_val_score(cls,X,y,cv=ns)\n",
    "    return print(\"Accuracy: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LRs(X,y,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support Vector Machines multilabel model function with crossvalidation\n",
    "def SVMs(X,y,ns):\n",
    "    cls = OneVsRestClassifier(svm.SVC(kernel='rbf',probability=True,gamma='auto'))\n",
    "    scores = cross_val_score(cls,X,y,cv=ns)\n",
    "    return print(\"Accuracy: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVMs(X,y,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest multilabel model function with crossvalidation\n",
    "def RFs(X,y,n,ns):\n",
    "    cls = OneVsRestClassifier(RandomForestClassifier(n_estimators=n))\n",
    "    scores = cross_val_score(cls,X,y,cv=ns)\n",
    "    return print(\"Accuracy: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFs(X,y,20,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K Neighbors multilabel model function with crossvalidation\n",
    "def KNNs(X,y,k,ns):\n",
    "    cls = OneVsRestClassifier(KNeighborsClassifier(n_neighbors=k))\n",
    "    scores = cross_val_score(cls,X,y,cv=ns)\n",
    "    return print(\"Accuracy: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNNs(X,y,10,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20,random_state=42)\n",
    "display(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = OneVsRestClassifier(RandomForestClassifier(n_estimators=20))\n",
    "cls.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cls.predict(X_test)\n",
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = cls.predict(X_test).argmax(axis=1)\n",
    "actual_values = y_test.values.argmax(axis=1)\n",
    "print(predictions,actual_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(actual_values, predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = pd.DataFrame(precision_score(actual_values, predictions, average=None))\n",
    "recall = pd.DataFrame(recall_score(actual_values, predictions, average=None))\n",
    "f1_score = pd.DataFrame(f1_score(actual_values, predictions, average=None))\n",
    "display(precision,recall,f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12,10))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(actual_values, predictions, y.columns, cmap='BuPu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(actual_values, predictions, y.columns, normalize=True, cmap='BuPu')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
